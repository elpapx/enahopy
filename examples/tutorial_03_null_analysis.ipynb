{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Tutorial 03: An√°lisis de Valores Faltantes\n",
    "\n",
    "Este tutorial cubre el uso del m√≥dulo **null_analysis** de enahopy para:\n",
    "- Analizar patrones de valores faltantes en datos ENAHO\n",
    "- Detectar columnas problem√°ticas\n",
    "- Generar reportes de calidad de datos\n",
    "- Aplicar estrategias de imputaci√≥n recomendadas\n",
    "\n",
    "## ¬øPor qu√© es importante?\n",
    "\n",
    "Los valores faltantes son comunes en encuestas como ENAHO debido a:\n",
    "- Preguntas condicionales (skip patterns)\n",
    "- No respuestas\n",
    "- Errores de captura\n",
    "- Casos no aplicables\n",
    "\n",
    "El an√°lisis adecuado permite identificar si los nulos son:\n",
    "- **MCAR** (Missing Completely At Random): Totalmente aleatorios\n",
    "- **MAR** (Missing At Random): Relacionados con variables observadas\n",
    "- **MNAR** (Missing Not At Random): Relacionados con valores no observados"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell-1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T20:32:23.847041600Z",
     "start_time": "2025-10-18T20:32:23.796657700Z"
    }
   },
   "source": "# Instalaci√≥n (si es necesario)\n# !pip install enahopy\n\nimport enahopy\nfrom enahopy.loader import ENAHODataDownloader\nfrom enahopy.loader.io import ENAHOLocalReader\nfrom enahopy.null_analysis import ENAHONullAnalyzer\nimport pandas as pd\nimport numpy as np\nimport warnings\nwarnings.filterwarnings('ignore')\n\nprint(f\"enahopy versi√≥n: {enahopy.__version__}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## 1. Cargar Datos con Valores Faltantes\n",
    "\n",
    "### 1.1 M√≥dulo 05 (Empleo e Ingresos)\n",
    "\n",
    "Este m√≥dulo tiene muchos valores faltantes debido a preguntas condicionales:\n",
    "- Ingresos solo aplican a trabajadores\n",
    "- Ciertas preguntas son solo para dependientes/independientes\n",
    "- Horas trabajadas solo para ocupados"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell-3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T20:26:39.103670900Z",
     "start_time": "2025-10-18T20:26:36.871327800Z"
    }
   },
   "source": [
    "year = 2022\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Inicializar lector\n",
    "dta_files_05 = glob.glob(f\".enaho_cache/modulo_05_{year}/*.dta\")\n",
    "file_path_05 = dta_files_05[0]\n",
    "reader_05 = ENAHOLocalReader(file_path=file_path_05, verbose=False)\n",
    "df_modulo05, validation_05 = reader_05.read_data(columns=[\n",
    "    'conglome', 'vivienda', 'hogar', 'codperso',  # Identificadores\n",
    "    'ocu500',   # Condici√≥n de actividad\n",
    "    'p506',      # Ocupaci√≥n principal\n",
    "    'p507',      # Categor√≠a ocupacional\n",
    "    'p511a',     # Horas trabajadas\n",
    "    'i524a1',    # Ingreso trabajo dependiente\n",
    "    'i530a',     # Ingreso trabajo independiente\n",
    "    'p523',      # Tiene contrato escrito\n",
    "    'p524a1'     # Tipo de contrato\n",
    "            ])\n",
    "print(f\"\\n‚úÖ Datos cargados:\")\n",
    "print(f\"   Filas: {len(df_modulo05):,}\")\n",
    "print(f\"   Columnas: {len(df_modulo05.columns)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Datos cargados:\n",
      "   Filas: 87,661\n",
      "   Columnas: 12\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "### 1.2 Exploraci√≥n Inicial de Nulos"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell-5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T20:26:53.424850Z",
     "start_time": "2025-10-18T20:26:53.340191500Z"
    }
   },
   "source": [
    "# Conteo b√°sico de nulos\n",
    "null_counts = df_modulo05.isnull().sum()\n",
    "null_pcts = (null_counts / len(df_modulo05) * 100).sort_values(ascending=False)\n",
    "\n",
    "print(\"üìä Top 15 columnas con m√°s valores faltantes:\")\n",
    "print(\"=\" * 60)\n",
    "for col, pct in null_pcts.head(15).items():\n",
    "    n_nulls = null_counts[col]\n",
    "    print(f\"{col:20s}: {n_nulls:6,} ({pct:5.1f}%)\")\n",
    "\n",
    "# Estad√≠sticas generales\n",
    "total_cells = df_modulo05.shape[0] * df_modulo05.shape[1]\n",
    "total_nulls = df_modulo05.isnull().sum().sum()\n",
    "null_rate = total_nulls / total_cells * 100\n",
    "\n",
    "print(f\"\\nüìà Estad√≠sticas generales:\")\n",
    "print(f\"   Total de celdas: {total_cells:,}\")\n",
    "print(f\"   Celdas con nulos: {total_nulls:,}\")\n",
    "print(f\"   Tasa de nulos: {null_rate:.2f}%\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Top 15 columnas con m√°s valores faltantes:\n",
      "============================================================\n",
      "p524a1              : 62,318 ( 71.1%)\n",
      "p523                : 62,021 ( 70.8%)\n",
      "i524a1              : 62,021 ( 70.8%)\n",
      "i530a               : 60,199 ( 68.7%)\n",
      "p511a               : 50,150 ( 57.2%)\n",
      "p506                : 22,421 ( 25.6%)\n",
      "p507                : 22,421 ( 25.6%)\n",
      "conglome            :      0 (  0.0%)\n",
      "vivienda            :      0 (  0.0%)\n",
      "hogar               :      0 (  0.0%)\n",
      "codperso            :      0 (  0.0%)\n",
      "ocu500              :      0 (  0.0%)\n",
      "\n",
      "üìà Estad√≠sticas generales:\n",
      "   Total de celdas: 1,051,932\n",
      "   Celdas con nulos: 341,551\n",
      "   Tasa de nulos: 32.47%\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## 2. An√°lisis Avanzado con ENAHONullAnalyzer\n",
    "\n",
    "### 2.1 Inicializar Analizador y Detectar Patrones"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell-7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T20:26:58.960446Z",
     "start_time": "2025-10-18T20:26:57.702032600Z"
    }
   },
   "source": [
    "# Inicializar analizador\n",
    "analyzer = ENAHONullAnalyzer(verbose=True)\n",
    "\n",
    "# Analizar dataset\n",
    "print(\"üîç Analizando patrones de valores faltantes...\\n\")\n",
    "result = analyzer.analyze(df_modulo05)\n",
    "\n",
    "print(f\"\\n‚úÖ An√°lisis completado:\")\n",
    "print(f\"   Patrones detectados: {len(result['patterns']) if isinstance(result['patterns'], list) else 'N/A'}\")\n",
    "print(f\"   Recomendaciones generadas: {len(result['recommendations'])}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Analizando patrones de valores faltantes...\n",
      "\n",
      "\n",
      "‚úÖ An√°lisis completado:\n",
      "   Patrones detectados: N/A\n",
      "   Recomendaciones generadas: 9\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "### 2.2 Examinar Patrones Detectados"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell-9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T20:27:04.672822400Z",
     "start_time": "2025-10-18T20:27:04.605496600Z"
    }
   },
   "source": [
    "# Ver informaci√≥n sobre patrones\n",
    "print(\"üîé Informaci√≥n de patrones de valores faltantes:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "patterns = result['patterns']\n",
    "if isinstance(patterns, dict):\n",
    "    print(f\"\\nTipo de patrones detectado: Diccionario\")\n",
    "    print(f\"Claves disponibles: {list(patterns.keys())}\")\n",
    "    for key, value in patterns.items():\n",
    "        print(f\"\\n  {key}: {value}\")\n",
    "elif isinstance(patterns, list) and len(patterns) > 0:\n",
    "    for i, pattern in enumerate(patterns[:5], 1):\n",
    "        print(f\"\\nPatr√≥n {i}:\")\n",
    "        print(f\"  Tipo: {pattern.get('type', 'N/A')}\")\n",
    "        print(f\"  Columnas afectadas: {len(pattern.get('columns', []))}\")\n",
    "        print(f\"  Severidad: {pattern.get('severity', 'N/A')}\")\n",
    "        if 'description' in pattern:\n",
    "            print(f\"  Descripci√≥n: {pattern['description']}\")\n",
    "else:\n",
    "    print(\"\\nNo se detectaron patrones espec√≠ficos o el an√°lisis est√° en progreso.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé Informaci√≥n de patrones de valores faltantes:\n",
      "======================================================================\n",
      "\n",
      "Tipo de patrones detectado: Diccionario\n",
      "Claves disponibles: ['global', 'numeric', 'categorical']\n",
      "\n",
      "  global: PatternResult(pattern_type=<MissingDataPattern.MNAR: 'Missing Not At Random'>, severity=<PatternSeverity.HIGH: 'high'>, affected_columns=['p506', 'p507', 'p511a', 'p523', 'p524a1', 'i530a', 'i524a1'], percentage_missing=32.46892384678858, confidence=0.8, details={'total_values': 1051932, 'null_values': 341551, 'overall_percentage': 32.46892384678858, 'columns_with_nulls': 7, 'rows_with_nulls': 87661, 'complete_rows': 0, 'complete_columns': 5, 'null_correlation_mean': nan}, recommendations=['Los datos no faltan aleatoriamente', 'Investigue las causas de los valores faltantes', 'Porcentaje significativo de datos faltantes'])\n",
      "\n",
      "  numeric: PatternResult(pattern_type=<MissingDataPattern.MNAR: 'Missing Not At Random'>, severity=<PatternSeverity.CRITICAL: 'critical'>, affected_columns=['i530a', 'i524a1'], percentage_missing=69.7117304160345, confidence=0.8, details={'total_values': 175322, 'null_values': 122220, 'overall_percentage': 69.7117304160345, 'columns_with_nulls': 2, 'rows_with_nulls': 87661, 'complete_rows': 0, 'complete_columns': 0, 'null_correlation_mean': -0.4342712423836088}, recommendations=['Los datos no faltan aleatoriamente', 'Investigue las causas de los valores faltantes', 'ADVERTENCIA: Alto porcentaje de datos faltantes'])\n",
      "\n",
      "  categorical: PatternResult(pattern_type=<MissingDataPattern.MNAR: 'Missing Not At Random'>, severity=<PatternSeverity.HIGH: 'high'>, affected_columns=['p506', 'p507', 'p511a', 'p523', 'p524a1'], percentage_missing=25.020362532939394, confidence=0.8, details={'total_values': 876610, 'null_values': 219331, 'overall_percentage': 25.020362532939394, 'columns_with_nulls': 5, 'rows_with_nulls': 62581, 'complete_rows': 25080, 'complete_columns': 5, 'null_correlation_mean': nan}, recommendations=['Los datos no faltan aleatoriamente', 'Investigue las causas de los valores faltantes', 'Porcentaje significativo de datos faltantes'])\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "### 2.3 Revisar Recomendaciones"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell-11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T20:35:29.334227300Z",
     "start_time": "2025-10-18T20:35:29.272546900Z"
    }
   },
   "source": "# Ver recomendaciones\nprint(\"üí° Recomendaciones para manejo de valores faltantes:\")\nprint(\"=\" * 70)\n\nrecommendations = result['recommendations']\nif len(recommendations) > 0:\n    for i, rec in enumerate(recommendations[:10], 1):\n        # Las recomendaciones pueden ser strings o dicts\n        if isinstance(rec, str):\n            print(f\"\\n{i}. {rec}\")\n        elif isinstance(rec, dict):\n            print(f\"\\n{i}. {rec.get('action', 'N/A')}\")\n            if 'columns' in rec:\n                print(f\"   Columnas: {', '.join(rec['columns'][:3])}...\" if len(rec['columns']) > 3 else f\"   Columnas: {', '.join(rec['columns'])}\")\n            if 'reason' in rec:\n                print(f\"   Raz√≥n: {rec['reason']}\")\n        else:\n            print(f\"\\n{i}. {rec}\")\nelse:\n    print(\"\\nNo se generaron recomendaciones espec√≠ficas.\")\n    print(\"Puede usar las estrategias generales seg√∫n el % de valores faltantes.\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí° Recomendaciones para manejo de valores faltantes:\n",
      "======================================================================\n",
      "\n",
      "1. Los datos no faltan aleatoriamente\n",
      "\n",
      "2. Investigue las causas de los valores faltantes\n",
      "\n",
      "3. Porcentaje significativo de datos faltantes\n",
      "\n",
      "4. Los datos no faltan aleatoriamente\n",
      "\n",
      "5. Investigue las causas de los valores faltantes\n",
      "\n",
      "6. ADVERTENCIA: Alto porcentaje de datos faltantes\n",
      "\n",
      "7. Los datos no faltan aleatoriamente\n",
      "\n",
      "8. Investigue las causas de los valores faltantes\n",
      "\n",
      "9. Porcentaje significativo de datos faltantes\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## 3. Generar Reportes Detallados\n",
    "\n",
    "### 3.1 Resumen del An√°lisis"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell-13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T20:35:36.619123200Z",
     "start_time": "2025-10-18T20:35:36.579296800Z"
    }
   },
   "source": [
    "# Mostrar resumen del an√°lisis\n",
    "print(\"üìã Resumen del An√°lisis de Valores Faltantes\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Resumen general\n",
    "if 'summary' in result:\n",
    "    print(\"\\nüìä Resumen General:\")\n",
    "    summary = result['summary']\n",
    "    if isinstance(summary, dict):\n",
    "        for key, value in summary.items():\n",
    "            if key not in ['columns_analysis', 'row_analysis', 'patterns']:\n",
    "                print(f\"   {key}: {value}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Resumen del An√°lisis de Valores Faltantes\n",
      "======================================================================\n",
      "\n",
      "üìä Resumen General:\n",
      "   shape: (87661, 12)\n",
      "   total_values: 1051932\n",
      "   null_values: 341551\n",
      "   null_percentage: 32.46892384678858\n",
      "   severity: high\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "### 3.2 An√°lisis de Correlaci√≥n de Nulos\n",
    "\n",
    "Identificar si los nulos en ciertas columnas est√°n correlacionados:"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell-15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T20:35:42.795640100Z",
     "start_time": "2025-10-18T20:35:42.745613900Z"
    }
   },
   "source": [
    "# Seleccionar columnas con >10% de nulos para an√°lisis de correlaci√≥n\n",
    "high_null_cols = null_pcts[null_pcts > 10].index[:10].tolist()\n",
    "\n",
    "if len(high_null_cols) >= 2:\n",
    "    # Crear matriz de indicadores de nulos\n",
    "    null_matrix = df_modulo05[high_null_cols].isnull().astype(int)\n",
    "    \n",
    "    # Calcular correlaci√≥n entre patrones de nulos\n",
    "    null_corr = null_matrix.corr()\n",
    "    \n",
    "    print(\"üîó Correlaci√≥n entre patrones de valores faltantes:\")\n",
    "    print(\"   (Valores altos indican que los nulos ocurren juntos)\\n\")\n",
    "    \n",
    "    # Encontrar pares con alta correlaci√≥n (>0.7)\n",
    "    high_corr_pairs = []\n",
    "    for i in range(len(null_corr.columns)):\n",
    "        for j in range(i+1, len(null_corr.columns)):\n",
    "            corr_val = null_corr.iloc[i, j]\n",
    "            if corr_val > 0.7:\n",
    "                high_corr_pairs.append((\n",
    "                    null_corr.columns[i],\n",
    "                    null_corr.columns[j],\n",
    "                    corr_val\n",
    "                ))\n",
    "    \n",
    "    if high_corr_pairs:\n",
    "        print(f\"   Pares con correlaci√≥n >0.7: {len(high_corr_pairs)}\\n\")\n",
    "        for col1, col2, corr in sorted(high_corr_pairs, key=lambda x: x[2], reverse=True)[:5]:\n",
    "            print(f\"   {col1} ‚Üî {col2}: {corr:.3f}\")\n",
    "    else:\n",
    "        print(\"   No se encontraron pares con correlaci√≥n >0.7\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó Correlaci√≥n entre patrones de valores faltantes:\n",
      "   (Valores altos indican que los nulos ocurren juntos)\n",
      "\n",
      "   Pares con correlaci√≥n >0.7: 7\n",
      "\n",
      "   p523 ‚Üî i524a1: 1.000\n",
      "   p506 ‚Üî p507: 1.000\n",
      "   p524a1 ‚Üî p523: 0.992\n",
      "   p524a1 ‚Üî i524a1: 0.992\n",
      "   p523 ‚Üî p511a: 0.730\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## 4. An√°lisis por Subgrupos\n",
    "\n",
    "### 4.1 Analizar Nulos por Condici√≥n de Actividad (ocu500)"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell-17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T20:35:47.469759400Z",
     "start_time": "2025-10-18T20:35:47.439407900Z"
    }
   },
   "source": [
    "# Verificar si existe la columna ocu500 (condici√≥n de actividad)\n",
    "if 'ocu500' in df_modulo05.columns:\n",
    "    print(\"üìä An√°lisis de nulos por Condici√≥n de Actividad (ocu500):\\n\")\n",
    "    \n",
    "    # Agrupar por condici√≥n de actividad\n",
    "    for category in df_modulo05['ocu500'].dropna().unique()[:3]:\n",
    "        subset = df_modulo05[df_modulo05['ocu500'] == category]\n",
    "        null_rate = subset.isnull().sum().sum() / (subset.shape[0] * subset.shape[1]) * 100\n",
    "        \n",
    "        print(f\"   Categor√≠a {category}: {null_rate:.2f}% nulos (n={len(subset):,})\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Columna 'ocu500' no encontrada en el dataset\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä An√°lisis de nulos por Condici√≥n de Actividad (ocu500):\n",
      "\n",
      "   Categor√≠a ocupado: 22.93% nulos (n=61,181)\n",
      "   Categor√≠a no pea: 54.42% nulos (n=23,460)\n",
      "   Categor√≠a desocupado abierto: 55.87% nulos (n=1,948)\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## 5. Estrategias de Imputaci√≥n\n",
    "\n",
    "### 5.1 Identificar Columnas Candidatas para Imputaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell-19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T20:35:50.916637300Z",
     "start_time": "2025-10-18T20:35:50.869483800Z"
    }
   },
   "source": [
    "# Categorizar columnas seg√∫n porcentaje de nulos\n",
    "low_null_cols = null_pcts[(null_pcts > 0) & (null_pcts < 5)].index.tolist()\n",
    "medium_null_cols = null_pcts[(null_pcts >= 5) & (null_pcts < 30)].index.tolist()\n",
    "high_null_cols = null_pcts[null_pcts >= 30].index.tolist()\n",
    "\n",
    "print(\"üéØ Clasificaci√≥n de columnas seg√∫n % de nulos:\\n\")\n",
    "print(f\"   Bajo (<5%):     {len(low_null_cols)} columnas\")\n",
    "print(f\"   Medio (5-30%):  {len(medium_null_cols)} columnas\")\n",
    "print(f\"   Alto (>30%):    {len(high_null_cols)} columnas\")\n",
    "\n",
    "print(\"\\nüí° Recomendaciones de estrategia:\")\n",
    "print(\"\\n   Bajo (<5%):\")\n",
    "print(\"   - Imputaci√≥n por media/mediana (num√©ricos)\")\n",
    "print(\"   - Imputaci√≥n por moda (categ√≥ricos)\")\n",
    "print(\"   - KNN imputation\")\n",
    "\n",
    "print(\"\\n   Medio (5-30%):\")\n",
    "print(\"   - An√°lisis de patrones antes de imputar\")\n",
    "print(\"   - Multiple imputation (MICE)\")\n",
    "print(\"   - Modelos predictivos\")\n",
    "\n",
    "print(\"\\n   Alto (>30%):\")\n",
    "print(\"   - Considerar eliminar columna\")\n",
    "print(\"   - Crear indicador de nulo\")\n",
    "print(\"   - Analizar si son nulos estructurales (skip patterns)\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Clasificaci√≥n de columnas seg√∫n % de nulos:\n",
      "\n",
      "   Bajo (<5%):     0 columnas\n",
      "   Medio (5-30%):  2 columnas\n",
      "   Alto (>30%):    5 columnas\n",
      "\n",
      "üí° Recomendaciones de estrategia:\n",
      "\n",
      "   Bajo (<5%):\n",
      "   - Imputaci√≥n por media/mediana (num√©ricos)\n",
      "   - Imputaci√≥n por moda (categ√≥ricos)\n",
      "   - KNN imputation\n",
      "\n",
      "   Medio (5-30%):\n",
      "   - An√°lisis de patrones antes de imputar\n",
      "   - Multiple imputation (MICE)\n",
      "   - Modelos predictivos\n",
      "\n",
      "   Alto (>30%):\n",
      "   - Considerar eliminar columna\n",
      "   - Crear indicador de nulo\n",
      "   - Analizar si son nulos estructurales (skip patterns)\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "### 5.2 Ejemplo: Imputaci√≥n Simple en Columnas de Bajo % de Nulos"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell-21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T20:35:58.599668500Z",
     "start_time": "2025-10-18T20:35:58.530956400Z"
    }
   },
   "source": [
    "# Seleccionar columnas num√©ricas con <5% de nulos\n",
    "numeric_cols = df_modulo05.select_dtypes(include=[np.number]).columns\n",
    "low_null_numeric = [col for col in low_null_cols if col in numeric_cols]\n",
    "\n",
    "if low_null_numeric:\n",
    "    # Tomar primera columna como ejemplo\n",
    "    example_col = low_null_numeric[0]\n",
    "    \n",
    "    print(f\"üìù Ejemplo de imputaci√≥n: {example_col}\\n\")\n",
    "    print(f\"   Valores faltantes: {df_modulo05[example_col].isnull().sum()} ({null_pcts[example_col]:.2f}%)\")\n",
    "    print(f\"   Media: {df_modulo05[example_col].mean():.2f}\")\n",
    "    print(f\"   Mediana: {df_modulo05[example_col].median():.2f}\")\n",
    "    \n",
    "    # Crear copia e imputar\n",
    "    df_imputed = df_modulo05.copy()\n",
    "    df_imputed[example_col] = df_imputed[example_col].fillna(df_imputed[example_col].median())\n",
    "    \n",
    "    print(f\"\\n   ‚úÖ Imputaci√≥n completada con mediana\")\n",
    "    print(f\"   Valores faltantes despu√©s: {df_imputed[example_col].isnull().sum()}\")\n",
    "else:\n",
    "    print(\"No hay columnas num√©ricas con <5% de nulos para ejemplo\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No hay columnas num√©ricas con <5% de nulos para ejemplo\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "## 6. An√°lisis de Datos Completos\n",
    "\n",
    "### 6.1 Filas Completamente Sin Nulos"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell-23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T20:36:04.780391300Z",
     "start_time": "2025-10-18T20:36:04.740199500Z"
    }
   },
   "source": [
    "# Identificar filas sin ning√∫n valor nulo\n",
    "complete_rows = df_modulo05.dropna(how='any')\n",
    "complete_pct = len(complete_rows) / len(df_modulo05) * 100\n",
    "\n",
    "print(f\"üìä An√°lisis de datos completos:\\n\")\n",
    "print(f\"   Total de filas: {len(df_modulo05):,}\")\n",
    "print(f\"   Filas completas (sin nulos): {len(complete_rows):,}\")\n",
    "print(f\"   Porcentaje de filas completas: {complete_pct:.2f}%\")\n",
    "\n",
    "# ¬øCu√°ntas columnas necesitar√≠amos eliminar para tener 50% de filas completas?\n",
    "cols_sorted_by_nulls = null_pcts.sort_values(ascending=False)\n",
    "df_temp = df_modulo05.copy()\n",
    "\n",
    "for i, col in enumerate(cols_sorted_by_nulls.index, 1):\n",
    "    if col in df_temp.columns:\n",
    "        df_temp = df_temp.drop(columns=[col])\n",
    "        complete_temp = df_temp.dropna(how='any')\n",
    "        pct_complete = len(complete_temp) / len(df_temp) * 100\n",
    "        \n",
    "        if pct_complete >= 50:\n",
    "            print(f\"\\n   üí° Para lograr 50% de filas completas:\")\n",
    "            print(f\"      Eliminar {i} columnas con m√°s nulos\")\n",
    "            print(f\"      Resultar√≠a en {len(complete_temp):,} filas completas ({pct_complete:.1f}%)\")\n",
    "            break"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä An√°lisis de datos completos:\n",
      "\n",
      "   Total de filas: 87,661\n",
      "   Filas completas (sin nulos): 0\n",
      "   Porcentaje de filas completas: 0.00%\n",
      "\n",
      "   üí° Para lograr 50% de filas completas:\n",
      "      Eliminar 5 columnas con m√°s nulos\n",
      "      Resultar√≠a en 65,240 filas completas (74.4%)\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "## 7. Mejores Pr√°cticas y Recomendaciones\n",
    "\n",
    "### Resumen de Aprendizajes"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell-25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T20:36:09.086523Z",
     "start_time": "2025-10-18T20:36:09.053697300Z"
    }
   },
   "source": [
    "print(\"=\"*70)\n",
    "print(\"üí° MEJORES PR√ÅCTICAS PARA MANEJO DE VALORES FALTANTES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\"\"\n",
    "1. SIEMPRE ANALIZAR ANTES DE IMPUTAR\n",
    "   ‚úì Usar ENAHONullAnalyzer para entender patrones\n",
    "   ‚úì Identificar si son nulos estructurales (skip patterns)\n",
    "   ‚úì Verificar correlaciones entre columnas con nulos\n",
    "\n",
    "2. ESTRATEGIAS SEG√öN % DE NULOS\n",
    "   ‚úì <5%: Imputaci√≥n simple (media/mediana/moda)\n",
    "   ‚úì 5-30%: An√°lisis detallado + MICE o modelos\n",
    "   ‚úì >30%: Considerar eliminar o crear indicador\n",
    "\n",
    "3. NULOS ESTRUCTURALES EN ENAHO\n",
    "   ‚úì Preguntas condicionales son la causa principal\n",
    "   ‚úì Ej: Ingresos solo para trabajadores (ocu500)\n",
    "   ‚úì NO imputar estos nulos - son leg√≠timos\n",
    "\n",
    "4. DOCUMENTAR DECISIONES\n",
    "   ‚úì Registrar qu√© columnas se imputaron\n",
    "   ‚úì Registrar m√©todo utilizado\n",
    "   ‚úì Comparar resultados antes/despu√©s\n",
    "\n",
    "5. VALIDAR DESPU√âS DE IMPUTAR\n",
    "   ‚úì Verificar distribuciones\n",
    "   ‚úì Comprobar rangos v√°lidos\n",
    "   ‚úì An√°lisis de sensibilidad\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*70)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üí° MEJORES PR√ÅCTICAS PARA MANEJO DE VALORES FALTANTES\n",
      "======================================================================\n",
      "\n",
      "1. SIEMPRE ANALIZAR ANTES DE IMPUTAR\n",
      "   ‚úì Usar ENAHONullAnalyzer para entender patrones\n",
      "   ‚úì Identificar si son nulos estructurales (skip patterns)\n",
      "   ‚úì Verificar correlaciones entre columnas con nulos\n",
      "\n",
      "2. ESTRATEGIAS SEG√öN % DE NULOS\n",
      "   ‚úì <5%: Imputaci√≥n simple (media/mediana/moda)\n",
      "   ‚úì 5-30%: An√°lisis detallado + MICE o modelos\n",
      "   ‚úì >30%: Considerar eliminar o crear indicador\n",
      "\n",
      "3. NULOS ESTRUCTURALES EN ENAHO\n",
      "   ‚úì Preguntas condicionales son la causa principal\n",
      "   ‚úì Ej: Ingresos solo para trabajadores (ocu500)\n",
      "   ‚úì NO imputar estos nulos - son leg√≠timos\n",
      "\n",
      "4. DOCUMENTAR DECISIONES\n",
      "   ‚úì Registrar qu√© columnas se imputaron\n",
      "   ‚úì Registrar m√©todo utilizado\n",
      "   ‚úì Comparar resultados antes/despu√©s\n",
      "\n",
      "5. VALIDAR DESPU√âS DE IMPUTAR\n",
      "   ‚úì Verificar distribuciones\n",
      "   ‚úì Comprobar rangos v√°lidos\n",
      "   ‚úì An√°lisis de sensibilidad\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "id": "cell-26",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "En este tutorial aprendiste a:\n",
    "\n",
    "1. ‚úÖ Cargar datos con valores faltantes usando `ENAHOLocalReader`\n",
    "2. ‚úÖ Realizar an√°lisis exploratorio de nulos\n",
    "3. ‚úÖ Usar `ENAHONullAnalyzer` para detectar patrones autom√°ticamente\n",
    "4. ‚úÖ Interpretar resultados del an√°lisis (diccionarios con patterns y recommendations)\n",
    "5. ‚úÖ Analizar correlaciones entre patrones de nulos\n",
    "6. ‚úÖ Identificar estrategias de imputaci√≥n apropiadas\n",
    "7. ‚úÖ Comparar calidad de datos entre subgrupos\n",
    "8. ‚úÖ Aplicar mejores pr√°cticas para manejo de valores faltantes\n",
    "\n",
    "### Pr√≥ximos Pasos\n",
    "\n",
    "- **Tutorial 04**: Pipeline completo integrando `loader` + `merger` + `null_analysis`\n",
    "- Aplicar estas t√©cnicas en an√°lisis reales de pobreza e inequidad\n",
    "- Experimentar con diferentes m√©todos de imputaci√≥n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
