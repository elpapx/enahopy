{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Tutorial 03: An√°lisis de Valores Faltantes\n",
    "\n",
    "Este tutorial cubre el uso del m√≥dulo **null_analysis** de enahopy para:\n",
    "- Analizar patrones de valores faltantes en datos ENAHO\n",
    "- Detectar columnas problem√°ticas\n",
    "- Generar reportes de calidad de datos\n",
    "- Aplicar estrategias de imputaci√≥n recomendadas\n",
    "\n",
    "## ¬øPor qu√© es importante?\n",
    "\n",
    "Los valores faltantes son comunes en encuestas como ENAHO debido a:\n",
    "- Preguntas condicionales (skip patterns)\n",
    "- No respuestas\n",
    "- Errores de captura\n",
    "- Casos no aplicables\n",
    "\n",
    "El an√°lisis adecuado permite identificar si los nulos son:\n",
    "- **MCAR** (Missing Completely At Random): Totalmente aleatorios\n",
    "- **MAR** (Missing At Random): Relacionados con variables observadas\n",
    "- **MNAR** (Missing Not At Random): Relacionados con valores no observados"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell-1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T20:32:23.847041600Z",
     "start_time": "2025-10-18T20:32:23.796657700Z"
    }
   },
   "source": "# Instalaci√≥n (si es necesario)\n# !pip install enahopy\n\nimport enahopy\nfrom enahopy.loader import ENAHODataDownloader\nfrom enahopy.loader.io import ENAHOLocalReader\nfrom enahopy.null_analysis import ENAHONullAnalyzer\nimport pandas as pd\nimport numpy as np\nimport warnings\nwarnings.filterwarnings('ignore')\n\nprint(f\"enahopy versi√≥n: {enahopy.__version__}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## 1. Cargar Datos con Valores Faltantes\n",
    "\n",
    "### 1.1 M√≥dulo 05 (Empleo e Ingresos)\n",
    "\n",
    "Este m√≥dulo tiene muchos valores faltantes debido a preguntas condicionales:\n",
    "- Ingresos solo aplican a trabajadores\n",
    "- Ciertas preguntas son solo para dependientes/independientes\n",
    "- Horas trabajadas solo para ocupados"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell-3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T20:26:39.103670900Z",
     "start_time": "2025-10-18T20:26:36.871327800Z"
    }
   },
   "source": [
    "year = 2022\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Inicializar lector\n",
    "dta_files_05 = glob.glob(f\".enaho_cache/modulo_05_{year}/*.dta\")\n",
    "file_path_05 = dta_files_05[0]\n",
    "reader_05 = ENAHOLocalReader(file_path=file_path_05, verbose=False)\n",
    "df_modulo05, validation_05 = reader_05.read_data(columns=[\n",
    "    'conglome', 'vivienda', 'hogar', 'codperso',  # Identificadores\n",
    "    'ocu500',   # Condici√≥n de actividad\n",
    "    'p506',      # Ocupaci√≥n principal\n",
    "    'p507',      # Categor√≠a ocupacional\n",
    "    'p511a',     # Horas trabajadas\n",
    "    'i524a1',    # Ingreso trabajo dependiente\n",
    "    'i530a',     # Ingreso trabajo independiente\n",
    "    'p523',      # Tiene contrato escrito\n",
    "    'p524a1'     # Tipo de contrato\n",
    "            ])\n",
    "print(f\"\\n‚úÖ Datos cargados:\")\n",
    "print(f\"   Filas: {len(df_modulo05):,}\")\n",
    "print(f\"   Columnas: {len(df_modulo05.columns)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Datos cargados:\n",
      "   Filas: 87,661\n",
      "   Columnas: 12\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "### 1.2 Exploraci√≥n Inicial de Nulos"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell-5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T20:26:53.424850Z",
     "start_time": "2025-10-18T20:26:53.340191500Z"
    }
   },
   "source": [
    "# Conteo b√°sico de nulos\n",
    "null_counts = df_modulo05.isnull().sum()\n",
    "null_pcts = (null_counts / len(df_modulo05) * 100).sort_values(ascending=False)\n",
    "\n",
    "print(\"üìä Top 15 columnas con m√°s valores faltantes:\")\n",
    "print(\"=\" * 60)\n",
    "for col, pct in null_pcts.head(15).items():\n",
    "    n_nulls = null_counts[col]\n",
    "    print(f\"{col:20s}: {n_nulls:6,} ({pct:5.1f}%)\")\n",
    "\n",
    "# Estad√≠sticas generales\n",
    "total_cells = df_modulo05.shape[0] * df_modulo05.shape[1]\n",
    "total_nulls = df_modulo05.isnull().sum().sum()\n",
    "null_rate = total_nulls / total_cells * 100\n",
    "\n",
    "print(f\"\\nüìà Estad√≠sticas generales:\")\n",
    "print(f\"   Total de celdas: {total_cells:,}\")\n",
    "print(f\"   Celdas con nulos: {total_nulls:,}\")\n",
    "print(f\"   Tasa de nulos: {null_rate:.2f}%\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Top 15 columnas con m√°s valores faltantes:\n",
      "============================================================\n",
      "p524a1              : 62,318 ( 71.1%)\n",
      "p523                : 62,021 ( 70.8%)\n",
      "i524a1              : 62,021 ( 70.8%)\n",
      "i530a               : 60,199 ( 68.7%)\n",
      "p511a               : 50,150 ( 57.2%)\n",
      "p506                : 22,421 ( 25.6%)\n",
      "p507                : 22,421 ( 25.6%)\n",
      "conglome            :      0 (  0.0%)\n",
      "vivienda            :      0 (  0.0%)\n",
      "hogar               :      0 (  0.0%)\n",
      "codperso            :      0 (  0.0%)\n",
      "ocu500              :      0 (  0.0%)\n",
      "\n",
      "üìà Estad√≠sticas generales:\n",
      "   Total de celdas: 1,051,932\n",
      "   Celdas con nulos: 341,551\n",
      "   Tasa de nulos: 32.47%\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## 2. An√°lisis Avanzado con ENAHONullAnalyzer\n",
    "\n",
    "### 2.1 Inicializar Analizador y Detectar Patrones"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell-7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T20:26:58.960446Z",
     "start_time": "2025-10-18T20:26:57.702032600Z"
    }
   },
   "source": [
    "# Inicializar analizador\n",
    "analyzer = ENAHONullAnalyzer(verbose=True)\n",
    "\n",
    "# Analizar dataset\n",
    "print(\"üîç Analizando patrones de valores faltantes...\\n\")\n",
    "result = analyzer.analyze(df_modulo05)\n",
    "\n",
    "print(f\"\\n‚úÖ An√°lisis completado:\")\n",
    "print(f\"   Patrones detectados: {len(result['patterns']) if isinstance(result['patterns'], list) else 'N/A'}\")\n",
    "print(f\"   Recomendaciones generadas: {len(result['recommendations'])}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Analizando patrones de valores faltantes...\n",
      "\n",
      "\n",
      "‚úÖ An√°lisis completado:\n",
      "   Patrones detectados: N/A\n",
      "   Recomendaciones generadas: 9\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "### 2.2 Examinar Patrones Detectados"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell-9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T20:27:04.672822400Z",
     "start_time": "2025-10-18T20:27:04.605496600Z"
    }
   },
   "source": [
    "# Ver informaci√≥n sobre patrones\n",
    "print(\"üîé Informaci√≥n de patrones de valores faltantes:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "patterns = result['patterns']\n",
    "if isinstance(patterns, dict):\n",
    "    print(f\"\\nTipo de patrones detectado: Diccionario\")\n",
    "    print(f\"Claves disponibles: {list(patterns.keys())}\")\n",
    "    for key, value in patterns.items():\n",
    "        print(f\"\\n  {key}: {value}\")\n",
    "elif isinstance(patterns, list) and len(patterns) > 0:\n",
    "    for i, pattern in enumerate(patterns[:5], 1):\n",
    "        print(f\"\\nPatr√≥n {i}:\")\n",
    "        print(f\"  Tipo: {pattern.get('type', 'N/A')}\")\n",
    "        print(f\"  Columnas afectadas: {len(pattern.get('columns', []))}\")\n",
    "        print(f\"  Severidad: {pattern.get('severity', 'N/A')}\")\n",
    "        if 'description' in pattern:\n",
    "            print(f\"  Descripci√≥n: {pattern['description']}\")\n",
    "else:\n",
    "    print(\"\\nNo se detectaron patrones espec√≠ficos o el an√°lisis est√° en progreso.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé Informaci√≥n de patrones de valores faltantes:\n",
      "======================================================================\n",
      "\n",
      "Tipo de patrones detectado: Diccionario\n",
      "Claves disponibles: ['global', 'numeric', 'categorical']\n",
      "\n",
      "  global: PatternResult(pattern_type=<MissingDataPattern.MNAR: 'Missing Not At Random'>, severity=<PatternSeverity.HIGH: 'high'>, affected_columns=['p506', 'p507', 'p511a', 'p523', 'p524a1', 'i530a', 'i524a1'], percentage_missing=32.46892384678858, confidence=0.8, details={'total_values': 1051932, 'null_values': 341551, 'overall_percentage': 32.46892384678858, 'columns_with_nulls': 7, 'rows_with_nulls': 87661, 'complete_rows': 0, 'complete_columns': 5, 'null_correlation_mean': nan}, recommendations=['Los datos no faltan aleatoriamente', 'Investigue las causas de los valores faltantes', 'Porcentaje significativo de datos faltantes'])\n",
      "\n",
      "  numeric: PatternResult(pattern_type=<MissingDataPattern.MNAR: 'Missing Not At Random'>, severity=<PatternSeverity.CRITICAL: 'critical'>, affected_columns=['i530a', 'i524a1'], percentage_missing=69.7117304160345, confidence=0.8, details={'total_values': 175322, 'null_values': 122220, 'overall_percentage': 69.7117304160345, 'columns_with_nulls': 2, 'rows_with_nulls': 87661, 'complete_rows': 0, 'complete_columns': 0, 'null_correlation_mean': -0.4342712423836088}, recommendations=['Los datos no faltan aleatoriamente', 'Investigue las causas de los valores faltantes', 'ADVERTENCIA: Alto porcentaje de datos faltantes'])\n",
      "\n",
      "  categorical: PatternResult(pattern_type=<MissingDataPattern.MNAR: 'Missing Not At Random'>, severity=<PatternSeverity.HIGH: 'high'>, affected_columns=['p506', 'p507', 'p511a', 'p523', 'p524a1'], percentage_missing=25.020362532939394, confidence=0.8, details={'total_values': 876610, 'null_values': 219331, 'overall_percentage': 25.020362532939394, 'columns_with_nulls': 5, 'rows_with_nulls': 62581, 'complete_rows': 25080, 'complete_columns': 5, 'null_correlation_mean': nan}, recommendations=['Los datos no faltan aleatoriamente', 'Investigue las causas de los valores faltantes', 'Porcentaje significativo de datos faltantes'])\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "### 2.3 Revisar Recomendaciones"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell-11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T20:27:21.707611300Z",
     "start_time": "2025-10-18T20:27:21.646109100Z"
    }
   },
   "source": "# Ver recomendaciones\nprint(\"üí° Recomendaciones para manejo de valores faltantes:\")\nprint(\"=\" * 70)\n\nrecommendations = result['recommendations']\nif len(recommendations) > 0:\n    for i, rec in enumerate(recommendations[:10], 1):\n        # Las recomendaciones pueden ser strings o dicts\n        if isinstance(rec, str):\n            print(f\"\\n{i}. {rec}\")\n        elif isinstance(rec, dict):\n            print(f\"\\n{i}. {rec.get('action', 'N/A')}\")\n            if 'columns' in rec:\n                print(f\"   Columnas: {', '.join(rec['columns'][:3])}...\" if len(rec['columns']) > 3 else f\"   Columnas: {', '.join(rec['columns'])}\")\n            if 'reason' in rec:\n                print(f\"   Raz√≥n: {rec['reason']}\")\n        else:\n            print(f\"\\n{i}. {rec}\")\nelse:\n    print(\"\\nNo se generaron recomendaciones espec√≠ficas.\")\n    print(\"Puede usar las estrategias generales seg√∫n el % de valores faltantes.\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## 3. Generar Reportes Detallados\n",
    "\n",
    "### 3.1 Resumen del An√°lisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar resumen del an√°lisis\n",
    "print(\"üìã Resumen del An√°lisis de Valores Faltantes\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Resumen general\n",
    "if 'summary' in result:\n",
    "    print(\"\\nüìä Resumen General:\")\n",
    "    summary = result['summary']\n",
    "    if isinstance(summary, dict):\n",
    "        for key, value in summary.items():\n",
    "            if key not in ['columns_analysis', 'row_analysis', 'patterns']:\n",
    "                print(f\"   {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "### 3.2 An√°lisis de Correlaci√≥n de Nulos\n",
    "\n",
    "Identificar si los nulos en ciertas columnas est√°n correlacionados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar columnas con >10% de nulos para an√°lisis de correlaci√≥n\n",
    "high_null_cols = null_pcts[null_pcts > 10].index[:10].tolist()\n",
    "\n",
    "if len(high_null_cols) >= 2:\n",
    "    # Crear matriz de indicadores de nulos\n",
    "    null_matrix = df_modulo05[high_null_cols].isnull().astype(int)\n",
    "    \n",
    "    # Calcular correlaci√≥n entre patrones de nulos\n",
    "    null_corr = null_matrix.corr()\n",
    "    \n",
    "    print(\"üîó Correlaci√≥n entre patrones de valores faltantes:\")\n",
    "    print(\"   (Valores altos indican que los nulos ocurren juntos)\\n\")\n",
    "    \n",
    "    # Encontrar pares con alta correlaci√≥n (>0.7)\n",
    "    high_corr_pairs = []\n",
    "    for i in range(len(null_corr.columns)):\n",
    "        for j in range(i+1, len(null_corr.columns)):\n",
    "            corr_val = null_corr.iloc[i, j]\n",
    "            if corr_val > 0.7:\n",
    "                high_corr_pairs.append((\n",
    "                    null_corr.columns[i],\n",
    "                    null_corr.columns[j],\n",
    "                    corr_val\n",
    "                ))\n",
    "    \n",
    "    if high_corr_pairs:\n",
    "        print(f\"   Pares con correlaci√≥n >0.7: {len(high_corr_pairs)}\\n\")\n",
    "        for col1, col2, corr in sorted(high_corr_pairs, key=lambda x: x[2], reverse=True)[:5]:\n",
    "            print(f\"   {col1} ‚Üî {col2}: {corr:.3f}\")\n",
    "    else:\n",
    "        print(\"   No se encontraron pares con correlaci√≥n >0.7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## 4. An√°lisis por Subgrupos\n",
    "\n",
    "### 4.1 Analizar Nulos por Condici√≥n de Actividad (ocu500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar si existe la columna ocu500 (condici√≥n de actividad)\n",
    "if 'ocu500' in df_modulo05.columns:\n",
    "    print(\"üìä An√°lisis de nulos por Condici√≥n de Actividad (ocu500):\\n\")\n",
    "    \n",
    "    # Agrupar por condici√≥n de actividad\n",
    "    for category in df_modulo05['ocu500'].dropna().unique()[:3]:\n",
    "        subset = df_modulo05[df_modulo05['ocu500'] == category]\n",
    "        null_rate = subset.isnull().sum().sum() / (subset.shape[0] * subset.shape[1]) * 100\n",
    "        \n",
    "        print(f\"   Categor√≠a {category}: {null_rate:.2f}% nulos (n={len(subset):,})\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Columna 'ocu500' no encontrada en el dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## 5. Estrategias de Imputaci√≥n\n",
    "\n",
    "### 5.1 Identificar Columnas Candidatas para Imputaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorizar columnas seg√∫n porcentaje de nulos\n",
    "low_null_cols = null_pcts[(null_pcts > 0) & (null_pcts < 5)].index.tolist()\n",
    "medium_null_cols = null_pcts[(null_pcts >= 5) & (null_pcts < 30)].index.tolist()\n",
    "high_null_cols = null_pcts[null_pcts >= 30].index.tolist()\n",
    "\n",
    "print(\"üéØ Clasificaci√≥n de columnas seg√∫n % de nulos:\\n\")\n",
    "print(f\"   Bajo (<5%):     {len(low_null_cols)} columnas\")\n",
    "print(f\"   Medio (5-30%):  {len(medium_null_cols)} columnas\")\n",
    "print(f\"   Alto (>30%):    {len(high_null_cols)} columnas\")\n",
    "\n",
    "print(\"\\nüí° Recomendaciones de estrategia:\")\n",
    "print(\"\\n   Bajo (<5%):\")\n",
    "print(\"   - Imputaci√≥n por media/mediana (num√©ricos)\")\n",
    "print(\"   - Imputaci√≥n por moda (categ√≥ricos)\")\n",
    "print(\"   - KNN imputation\")\n",
    "\n",
    "print(\"\\n   Medio (5-30%):\")\n",
    "print(\"   - An√°lisis de patrones antes de imputar\")\n",
    "print(\"   - Multiple imputation (MICE)\")\n",
    "print(\"   - Modelos predictivos\")\n",
    "\n",
    "print(\"\\n   Alto (>30%):\")\n",
    "print(\"   - Considerar eliminar columna\")\n",
    "print(\"   - Crear indicador de nulo\")\n",
    "print(\"   - Analizar si son nulos estructurales (skip patterns)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "### 5.2 Ejemplo: Imputaci√≥n Simple en Columnas de Bajo % de Nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar columnas num√©ricas con <5% de nulos\n",
    "numeric_cols = df_modulo05.select_dtypes(include=[np.number]).columns\n",
    "low_null_numeric = [col for col in low_null_cols if col in numeric_cols]\n",
    "\n",
    "if low_null_numeric:\n",
    "    # Tomar primera columna como ejemplo\n",
    "    example_col = low_null_numeric[0]\n",
    "    \n",
    "    print(f\"üìù Ejemplo de imputaci√≥n: {example_col}\\n\")\n",
    "    print(f\"   Valores faltantes: {df_modulo05[example_col].isnull().sum()} ({null_pcts[example_col]:.2f}%)\")\n",
    "    print(f\"   Media: {df_modulo05[example_col].mean():.2f}\")\n",
    "    print(f\"   Mediana: {df_modulo05[example_col].median():.2f}\")\n",
    "    \n",
    "    # Crear copia e imputar\n",
    "    df_imputed = df_modulo05.copy()\n",
    "    df_imputed[example_col] = df_imputed[example_col].fillna(df_imputed[example_col].median())\n",
    "    \n",
    "    print(f\"\\n   ‚úÖ Imputaci√≥n completada con mediana\")\n",
    "    print(f\"   Valores faltantes despu√©s: {df_imputed[example_col].isnull().sum()}\")\n",
    "else:\n",
    "    print(\"No hay columnas num√©ricas con <5% de nulos para ejemplo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "## 6. An√°lisis de Datos Completos\n",
    "\n",
    "### 6.1 Filas Completamente Sin Nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar filas sin ning√∫n valor nulo\n",
    "complete_rows = df_modulo05.dropna(how='any')\n",
    "complete_pct = len(complete_rows) / len(df_modulo05) * 100\n",
    "\n",
    "print(f\"üìä An√°lisis de datos completos:\\n\")\n",
    "print(f\"   Total de filas: {len(df_modulo05):,}\")\n",
    "print(f\"   Filas completas (sin nulos): {len(complete_rows):,}\")\n",
    "print(f\"   Porcentaje de filas completas: {complete_pct:.2f}%\")\n",
    "\n",
    "# ¬øCu√°ntas columnas necesitar√≠amos eliminar para tener 50% de filas completas?\n",
    "cols_sorted_by_nulls = null_pcts.sort_values(ascending=False)\n",
    "df_temp = df_modulo05.copy()\n",
    "\n",
    "for i, col in enumerate(cols_sorted_by_nulls.index, 1):\n",
    "    if col in df_temp.columns:\n",
    "        df_temp = df_temp.drop(columns=[col])\n",
    "        complete_temp = df_temp.dropna(how='any')\n",
    "        pct_complete = len(complete_temp) / len(df_temp) * 100\n",
    "        \n",
    "        if pct_complete >= 50:\n",
    "            print(f\"\\n   üí° Para lograr 50% de filas completas:\")\n",
    "            print(f\"      Eliminar {i} columnas con m√°s nulos\")\n",
    "            print(f\"      Resultar√≠a en {len(complete_temp):,} filas completas ({pct_complete:.1f}%)\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "## 7. Mejores Pr√°cticas y Recomendaciones\n",
    "\n",
    "### Resumen de Aprendizajes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"üí° MEJORES PR√ÅCTICAS PARA MANEJO DE VALORES FALTANTES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\"\"\n",
    "1. SIEMPRE ANALIZAR ANTES DE IMPUTAR\n",
    "   ‚úì Usar ENAHONullAnalyzer para entender patrones\n",
    "   ‚úì Identificar si son nulos estructurales (skip patterns)\n",
    "   ‚úì Verificar correlaciones entre columnas con nulos\n",
    "\n",
    "2. ESTRATEGIAS SEG√öN % DE NULOS\n",
    "   ‚úì <5%: Imputaci√≥n simple (media/mediana/moda)\n",
    "   ‚úì 5-30%: An√°lisis detallado + MICE o modelos\n",
    "   ‚úì >30%: Considerar eliminar o crear indicador\n",
    "\n",
    "3. NULOS ESTRUCTURALES EN ENAHO\n",
    "   ‚úì Preguntas condicionales son la causa principal\n",
    "   ‚úì Ej: Ingresos solo para trabajadores (ocu500)\n",
    "   ‚úì NO imputar estos nulos - son leg√≠timos\n",
    "\n",
    "4. DOCUMENTAR DECISIONES\n",
    "   ‚úì Registrar qu√© columnas se imputaron\n",
    "   ‚úì Registrar m√©todo utilizado\n",
    "   ‚úì Comparar resultados antes/despu√©s\n",
    "\n",
    "5. VALIDAR DESPU√âS DE IMPUTAR\n",
    "   ‚úì Verificar distribuciones\n",
    "   ‚úì Comprobar rangos v√°lidos\n",
    "   ‚úì An√°lisis de sensibilidad\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-26",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "En este tutorial aprendiste a:\n",
    "\n",
    "1. ‚úÖ Cargar datos con valores faltantes usando `ENAHOLocalReader`\n",
    "2. ‚úÖ Realizar an√°lisis exploratorio de nulos\n",
    "3. ‚úÖ Usar `ENAHONullAnalyzer` para detectar patrones autom√°ticamente\n",
    "4. ‚úÖ Interpretar resultados del an√°lisis (diccionarios con patterns y recommendations)\n",
    "5. ‚úÖ Analizar correlaciones entre patrones de nulos\n",
    "6. ‚úÖ Identificar estrategias de imputaci√≥n apropiadas\n",
    "7. ‚úÖ Comparar calidad de datos entre subgrupos\n",
    "8. ‚úÖ Aplicar mejores pr√°cticas para manejo de valores faltantes\n",
    "\n",
    "### Pr√≥ximos Pasos\n",
    "\n",
    "- **Tutorial 04**: Pipeline completo integrando `loader` + `merger` + `null_analysis`\n",
    "- Aplicar estas t√©cnicas en an√°lisis reales de pobreza e inequidad\n",
    "- Experimentar con diferentes m√©todos de imputaci√≥n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}